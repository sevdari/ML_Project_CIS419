{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd\n",
    "\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic cleaning\n",
    "import time\n",
    "\n",
    "#data = data.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"})\n",
    "#data = data[data['HelpfulnessNumerator'] <= data['HelpfulnessDenominator']]\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#stop = set(stopwords.words('english'))\n",
    "\n",
    "#removing spaces and stopwords\n",
    "import re\n",
    "# function to clean data\n",
    "def clean_data(X):\n",
    "    temp =[]\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "    start = time.time()\n",
    "    for i, sentence in enumerate(X):\n",
    "        if i%10000 == 0:\n",
    "            print(i, 'Time taken:', time.time()-start)\n",
    "            start = time.time()\n",
    "        sentence = sentence.lower()                 # Converting to lowercase\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        sentence = re.sub(cleanr, ' ', sentence)        #Removing HTML tags\n",
    "        sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "        sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)        #Removing Punctuations\n",
    "\n",
    "        words = [snow.stem(word) for word in sentence.split()]   # Stemming\n",
    "        temp.append(words)\n",
    "\n",
    "    X = temp    \n",
    "\n",
    "    sent = []\n",
    "    for row in X:\n",
    "        sequ = ''\n",
    "        for word in row:\n",
    "            sequ = sequ + ' ' + word\n",
    "        sent.append(sequ)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv(\"C:/Users/micha/Downloads/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = cleaned_data['Text'], cleaned_data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Val Test Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[6240, 103101, 132012, 118346, 69678, 88065, 77283, 67678, 11370, 119636, 103058, 84350, 127436, 82990, 48312, 26324, 3711, 44976, 10303, 11962, 131641, 45099, 81899, 107770, 42312, 17753, 74373, 49704, 52256, 70211, 45685, 126593, 65367, 63933, 82366, 126367, 20829, 125395, 95147, 39374, 20359, 77745, 115421, 83684, 97041, 22449, 107053, 89064, 128864, 96635, 112664, 11635, 94570, 80720, 119419, 21796, 79041, 130782, 76993, 41201, 66625, 58450, 27695, 122371, 6787, 99336, 106295, 32975, 27402, 39926, 2721, 65128, 99464, 55611, 58617, 39928, 37133, 128457, 62765, 93617, 75491, 107562, 22642, 88431, 32381, 125915, 12183, 74898, 120600, 15992, 65734, 60435, 108560, 117120, 116485, 111626, 13633, 7476, 70581, 7023, 96693, 2479, 72222, 64377, 124719, 110532, 48584, 31094, 93922, 58788, 97901, 107225, 83495, 134209, 24437, 23667, 77749, 94509, 61308, 53613, 101388, 52441, 69710, 15713, 70751, 135790, 19296, 23377, 31911, 48282, 11155, 19377, 34810, 29628, 81882, 96308, 42238, 84278, 17713, 46880, 131277, 33572, 18124, 127190, 12489, 130445, 5210, 28592, 88614, 75006, 128809, 54442, 88386, 67049, 114195, 23330, 70278, 62949, 119173, 19384, 53207, 115040, 127569, 10461, 101602, 100471, 126351, 81693, 32782, 53885, 74919, 121867, 55905, 102024, 3993, 83428, 92480, 45167, 113042, 111441, 86933, 5479, 44140, 96713, 111536, 75007, 62210, 20633, 120394, 15590, 95545, 51741, 93583, 66047, 108218, 126642, 10653, 21672, 29692, 128655, 101506, 23308, 130077, 54804, 119995, 109993, 56207, 29064, 131872, 109288, 81027, 72431, 61262, 58947, 123157, 107943, 55620, 50157, 73943, 119915, 125663, 100445, 64864, 56401, 109366, 3404, 16200, 68142, 107690, 77879, 134736, 88323, 41639, 125071, 68500, 115670, 39804, 109456, 116360, 125325, 97307, 2374, 74410, 19042, 1888, 88486, 64791, 14474, 13136, 22836, 81230, 59115, 80840, 96049, 46580, 89783, 84183, 18888, 131491, 113246, 74715, 111745, 63313, 126606, 96523, 91601, 56708, 29696, 72578, 115728, 122441, 53889, 108927, 47063, 8090, 50323, 58381, 55263, 93263, 13252, 105345, 85622, 17292, 91011, 56599, 70739, 136859, 117521, 20985, 76304, 120348, 124855, 76414, 43209, 47851, 42518, 17877, 7286, 80329, 132290, 47538, 22376, 28340, 134690, 74734, 10627, 85419, 32691, 121802, 136610, 72203, 87782, 96291, 118125, 7703, 87233, 87505, 49032, 92602, 108366, 45697, 95329, 79785, 51505, 591, 48657, 98897, 71537, 95203, 21179, 34519, 79410, 85572, 56454, 35373, 27223, 81261, 38050, 72515, 136432, 59906, 26678, 23490, 36764, 92264, 1401, 136232, 136367, 75801, 127997, 84566, 27533, 130556, 122144, 6114, 68929, 67108, 112109, 53966, 27993, 137147, 58773, 26137, 20256, 131393, 89962, 130007, 22848, 119737, 35837, 9339, 11050, 70144, 46135, 13938, 59899, 29586, 31388, 81225, 32421, 61145, 33947, 102080, 33726, 135959, 23673, 81922, 2195, 72696, 22830, 78899, 57282, 38148, 67822, 68114, 53717, 9784, 5627, 32814, 68395, 38467, 44483, 18543, 88516, 50027, 89028, 30684, 71647, 22197, 61974, 21673, 45502, 93934, 64241, 74004, 60100, 74862, 60168, 34126, 132299, 31363, 122670, 45633, 43808, 26514, 71706, 49810, 16181, 46403, 101457, 19506, 101309, 43299, 52601, 79569, 106259, 37709, 111329, 28945, 91207, 114993, 80271, 97552, 114901, 9596, 38964, 10844, 95678, 57943, 132117, 64707, 116856, 34824, 54399, 57302, 14651, 72664, 37706, 51786, 106300, 33929, 127889, 11870, 108109, 122105, 66616, 81110, 130250, 19595, 86324, 99768, 6506, 127551, 69863, 75195, 20394, 106420, 111489, 91399, 91208, 72535, 11213, 54316, 36138, 50799, 81561, 87348, 45914, 137048, 70225, 134345, 7322, 37663, 53965, 17584, 4681, 106054, 5964, 88082, 7773, 57874, 12783, 69322, 28131, 35654, 82277, 435, 42510, 20952, 106626, 22530, 102456, 126668, 122445, 117612, 115357, 6896, 47698, 77856, 47559, 14715, 32450, 53777, 96717, 124596, 132050, 40406, 83009, 18987, 38071, 76073, 137030, 44555, 47971, 1744, 134727, 121848, 14184, 71794, 10239, 36225, 114078, 127760, 93060, 40574, 13327, 107352, 49271, 9454, 78348, 3971, 14330, 69324, 83052, 129167, 97558, 14645, 97484, 70049, 46633, 87065, 93671, 20846, 10825, 9323, 9405, 40004, 119013, 114428, 12045, 85157, 92281, 31398, 77054, 53347, 126837, 122671, 76362, 49978, 97755, 27341, 85268, 10550, 117515, 108397, 73712, 7893, 70950, 32702, 15996, 91233, 830, 111734, 121951, 85437, 137808, 99613, 129486, 126453, 14242, 135650, 98973, 57520, 41957, 127303, 43683, 119353, 55573, 11174, 120117, 5815, 46554, 83167, 238, 31018, 121797, 52966, 126800, 103948, 86817, 41262, 42058, 134780, 122725, 119833, 42653, 55349, 83965, 112190, 15937, 88731, 75176, 21071, 58509, 100256, 40626, 5461, 86240, 53760, 6426, 17485, 104717, 79803, 62224, 80267, 88843, 13885, 110863, 99062, 122601, 111379] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6136\\4167040307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbal_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Print the size and distribution of each set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6136\\4167040307.py\u001b[0m in \u001b[0;36mbal_split\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mpositive_val_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_val_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnegative_val_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_val_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mX_val_balanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpositive_val_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnegative_val_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0my_val_balanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1017\u001b[0m             \u001b[1;31m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1192\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5859\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5861\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[6240, 103101, 132012, 118346, 69678, 88065, 77283, 67678, 11370, 119636, 103058, 84350, 127436, 82990, 48312, 26324, 3711, 44976, 10303, 11962, 131641, 45099, 81899, 107770, 42312, 17753, 74373, 49704, 52256, 70211, 45685, 126593, 65367, 63933, 82366, 126367, 20829, 125395, 95147, 39374, 20359, 77745, 115421, 83684, 97041, 22449, 107053, 89064, 128864, 96635, 112664, 11635, 94570, 80720, 119419, 21796, 79041, 130782, 76993, 41201, 66625, 58450, 27695, 122371, 6787, 99336, 106295, 32975, 27402, 39926, 2721, 65128, 99464, 55611, 58617, 39928, 37133, 128457, 62765, 93617, 75491, 107562, 22642, 88431, 32381, 125915, 12183, 74898, 120600, 15992, 65734, 60435, 108560, 117120, 116485, 111626, 13633, 7476, 70581, 7023, 96693, 2479, 72222, 64377, 124719, 110532, 48584, 31094, 93922, 58788, 97901, 107225, 83495, 134209, 24437, 23667, 77749, 94509, 61308, 53613, 101388, 52441, 69710, 15713, 70751, 135790, 19296, 23377, 31911, 48282, 11155, 19377, 34810, 29628, 81882, 96308, 42238, 84278, 17713, 46880, 131277, 33572, 18124, 127190, 12489, 130445, 5210, 28592, 88614, 75006, 128809, 54442, 88386, 67049, 114195, 23330, 70278, 62949, 119173, 19384, 53207, 115040, 127569, 10461, 101602, 100471, 126351, 81693, 32782, 53885, 74919, 121867, 55905, 102024, 3993, 83428, 92480, 45167, 113042, 111441, 86933, 5479, 44140, 96713, 111536, 75007, 62210, 20633, 120394, 15590, 95545, 51741, 93583, 66047, 108218, 126642, 10653, 21672, 29692, 128655, 101506, 23308, 130077, 54804, 119995, 109993, 56207, 29064, 131872, 109288, 81027, 72431, 61262, 58947, 123157, 107943, 55620, 50157, 73943, 119915, 125663, 100445, 64864, 56401, 109366, 3404, 16200, 68142, 107690, 77879, 134736, 88323, 41639, 125071, 68500, 115670, 39804, 109456, 116360, 125325, 97307, 2374, 74410, 19042, 1888, 88486, 64791, 14474, 13136, 22836, 81230, 59115, 80840, 96049, 46580, 89783, 84183, 18888, 131491, 113246, 74715, 111745, 63313, 126606, 96523, 91601, 56708, 29696, 72578, 115728, 122441, 53889, 108927, 47063, 8090, 50323, 58381, 55263, 93263, 13252, 105345, 85622, 17292, 91011, 56599, 70739, 136859, 117521, 20985, 76304, 120348, 124855, 76414, 43209, 47851, 42518, 17877, 7286, 80329, 132290, 47538, 22376, 28340, 134690, 74734, 10627, 85419, 32691, 121802, 136610, 72203, 87782, 96291, 118125, 7703, 87233, 87505, 49032, 92602, 108366, 45697, 95329, 79785, 51505, 591, 48657, 98897, 71537, 95203, 21179, 34519, 79410, 85572, 56454, 35373, 27223, 81261, 38050, 72515, 136432, 59906, 26678, 23490, 36764, 92264, 1401, 136232, 136367, 75801, 127997, 84566, 27533, 130556, 122144, 6114, 68929, 67108, 112109, 53966, 27993, 137147, 58773, 26137, 20256, 131393, 89962, 130007, 22848, 119737, 35837, 9339, 11050, 70144, 46135, 13938, 59899, 29586, 31388, 81225, 32421, 61145, 33947, 102080, 33726, 135959, 23673, 81922, 2195, 72696, 22830, 78899, 57282, 38148, 67822, 68114, 53717, 9784, 5627, 32814, 68395, 38467, 44483, 18543, 88516, 50027, 89028, 30684, 71647, 22197, 61974, 21673, 45502, 93934, 64241, 74004, 60100, 74862, 60168, 34126, 132299, 31363, 122670, 45633, 43808, 26514, 71706, 49810, 16181, 46403, 101457, 19506, 101309, 43299, 52601, 79569, 106259, 37709, 111329, 28945, 91207, 114993, 80271, 97552, 114901, 9596, 38964, 10844, 95678, 57943, 132117, 64707, 116856, 34824, 54399, 57302, 14651, 72664, 37706, 51786, 106300, 33929, 127889, 11870, 108109, 122105, 66616, 81110, 130250, 19595, 86324, 99768, 6506, 127551, 69863, 75195, 20394, 106420, 111489, 91399, 91208, 72535, 11213, 54316, 36138, 50799, 81561, 87348, 45914, 137048, 70225, 134345, 7322, 37663, 53965, 17584, 4681, 106054, 5964, 88082, 7773, 57874, 12783, 69322, 28131, 35654, 82277, 435, 42510, 20952, 106626, 22530, 102456, 126668, 122445, 117612, 115357, 6896, 47698, 77856, 47559, 14715, 32450, 53777, 96717, 124596, 132050, 40406, 83009, 18987, 38071, 76073, 137030, 44555, 47971, 1744, 134727, 121848, 14184, 71794, 10239, 36225, 114078, 127760, 93060, 40574, 13327, 107352, 49271, 9454, 78348, 3971, 14330, 69324, 83052, 129167, 97558, 14645, 97484, 70049, 46633, 87065, 93671, 20846, 10825, 9323, 9405, 40004, 119013, 114428, 12045, 85157, 92281, 31398, 77054, 53347, 126837, 122671, 76362, 49978, 97755, 27341, 85268, 10550, 117515, 108397, 73712, 7893, 70950, 32702, 15996, 91233, 830, 111734, 121951, 85437, 137808, 99613, 129486, 126453, 14242, 135650, 98973, 57520, 41957, 127303, 43683, 119353, 55573, 11174, 120117, 5815, 46554, 83167, 238, 31018, 121797, 52966, 126800, 103948, 86817, 41262, 42058, 134780, 122725, 119833, 42653, 55349, 83965, 112190, 15937, 88731, 75176, 21071, 58509, 100256, 40626, 5461, 86240, 53760, 6426, 17485, 104717, 79803, 62224, 80267, 88843, 13885, 110863, 99062, 122601, 111379] not in index'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def bal_split(X,y):\n",
    "    # Split the data into training and testing sets (70-30 split)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    # Split the remaining data into training and validation sets (50-50 split)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "    # Balance the VALIDATION set\n",
    "    positive_val_indices = np.where(y_val == 1)[0]\n",
    "    negative_val_indices = np.where(y_val == 0)[0]\n",
    "    np.random.seed(42)\n",
    "    positive_val_indices = np.random.choice(positive_val_indices, size=1000, replace=False)\n",
    "    negative_val_indices = np.random.choice(negative_val_indices, size=1000, replace=False)\n",
    "    X_val_balanced = np.concatenate((X_val[positive_val_indices], X_val[negative_val_indices]), axis=0)\n",
    "    y_val_balanced = np.concatenate((np.ones(1000), np.zeros(1000)))\n",
    "\n",
    "    return X_train, X_val_balanced, X_test, y_train, y_val_balanced, y_test\n",
    "\n",
    "\n",
    "\n",
    "# Print the size and distribution of each set\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Distribution of labels in training set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print()\n",
    "print(\"Size of test set:\", len(X_test))\n",
    "print(\"Distribution of labels in validation set:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "print()\n",
    "print(\"Size of balanced val set:\", len(X_val_balanced))\n",
    "print(\"Distribution of labels in balanced test set:\")\n",
    "print(pd.Series(y_val_balanced).value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completely Naive BoW with Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Convert text data to bag of words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Prediction\n",
    "lr_naive = LogisticRegression()\n",
    "lr_naive.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing dataset\n",
    "y_pred = lr_naive.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#88.4% out of the box accuracy on regular data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Convert text data to bag of words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, train_size = .7, test_size=0.01, random_state=42)\n",
    "\n",
    "# Calculate frequency of each class in the training set\n",
    "class_freq = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Split testing set into two parts, one for each class\n",
    "pos_idx = np.where(y_test == 1)[0]\n",
    "neg_idx = np.where(y_test == 0)[0]\n",
    "\n",
    "pos_test_set = X_test[pos_idx]\n",
    "neg_test_set = X_test[neg_idx]\n",
    "\n",
    "pos_test_set = pos_test_set.toarray()\n",
    "neg_test_set = neg_test_set.toarray()\n",
    "\n",
    "# Combine the two testing sets to create a balanced testing set\n",
    "min_len = min(pos_test_set.shape[0], neg_test_set.shape[0])\n",
    "\n",
    "balanced_X_test = np.concatenate((pos_test_set[:min_len], neg_test_set[:min_len]))\n",
    "balanced_y_test = np.concatenate((np.ones(min_len), np.zeros(min_len)))\n",
    "\n",
    "# Shuffle the examples in the balanced testing set\n",
    "shuffle_idx = np.random.permutation(len(balanced_y_test))\n",
    "balanced_X_test = balanced_X_test[shuffle_idx]\n",
    "balanced_y_test = balanced_y_test[shuffle_idx]\n",
    "\n",
    "# Train logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing dataset\n",
    "y_pred = lr.predict(balanced_X_test)\n",
    "\n",
    "y_pred_naive = lr_naive.predict(balanced_X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(balanced_y_test, y_pred)\n",
    "accuracy_naive = accuracy_score(balanced_y_test, y_pred_naive)\n",
    "\n",
    "\n",
    "\n",
    "#Accuracy 81% on balanced panel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    862\n",
      "0.0    862\n",
      "dtype: int64\n",
      "Accuracy: 0.810\n",
      "Naive Accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(balanced_y_test).value_counts())\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Naive Accuracy: {accuracy_naive:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample: 89.58%\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.3, random_state=42)\n",
    "accuracy = lr.score (X_test,y_test)\n",
    "print('Accuracy on random sample: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "#89% accuracy on random sample "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.58410\n",
      "[1]\ttest-logloss:0.52431\n",
      "[2]\ttest-logloss:0.48875\n",
      "[3]\ttest-logloss:0.46518\n",
      "[4]\ttest-logloss:0.44845\n",
      "[5]\ttest-logloss:0.43597\n",
      "[6]\ttest-logloss:0.42539\n",
      "[7]\ttest-logloss:0.41787\n",
      "[8]\ttest-logloss:0.41111\n",
      "[9]\ttest-logloss:0.40497\n",
      "[10]\ttest-logloss:0.39932\n",
      "[11]\ttest-logloss:0.39470\n",
      "[12]\ttest-logloss:0.38928\n",
      "[13]\ttest-logloss:0.38553\n",
      "[14]\ttest-logloss:0.38167\n",
      "[15]\ttest-logloss:0.37752\n",
      "[16]\ttest-logloss:0.37365\n",
      "[17]\ttest-logloss:0.37069\n",
      "[18]\ttest-logloss:0.36773\n",
      "[19]\ttest-logloss:0.36498\n",
      "[20]\ttest-logloss:0.36281\n",
      "[21]\ttest-logloss:0.36031\n",
      "[22]\ttest-logloss:0.35754\n",
      "[23]\ttest-logloss:0.35540\n",
      "[24]\ttest-logloss:0.35408\n",
      "[25]\ttest-logloss:0.35234\n",
      "[26]\ttest-logloss:0.35038\n",
      "[27]\ttest-logloss:0.34849\n",
      "[28]\ttest-logloss:0.34648\n",
      "[29]\ttest-logloss:0.34345\n",
      "[30]\ttest-logloss:0.34244\n",
      "[31]\ttest-logloss:0.34082\n",
      "[32]\ttest-logloss:0.33863\n",
      "[33]\ttest-logloss:0.33703\n",
      "[34]\ttest-logloss:0.33516\n",
      "[35]\ttest-logloss:0.33441\n",
      "[36]\ttest-logloss:0.33348\n",
      "[37]\ttest-logloss:0.33218\n",
      "[38]\ttest-logloss:0.33061\n",
      "[39]\ttest-logloss:0.32975\n",
      "[40]\ttest-logloss:0.32885\n",
      "[41]\ttest-logloss:0.32815\n",
      "[42]\ttest-logloss:0.32669\n",
      "[43]\ttest-logloss:0.32545\n",
      "[44]\ttest-logloss:0.32419\n",
      "[45]\ttest-logloss:0.32230\n",
      "[46]\ttest-logloss:0.32121\n",
      "[47]\ttest-logloss:0.32008\n",
      "[48]\ttest-logloss:0.31933\n",
      "[49]\ttest-logloss:0.31840\n",
      "[50]\ttest-logloss:0.31706\n",
      "[51]\ttest-logloss:0.31664\n",
      "[52]\ttest-logloss:0.31617\n",
      "[53]\ttest-logloss:0.31546\n",
      "[54]\ttest-logloss:0.31421\n",
      "[55]\ttest-logloss:0.31354\n",
      "[56]\ttest-logloss:0.31270\n",
      "[57]\ttest-logloss:0.31222\n",
      "[58]\ttest-logloss:0.31159\n",
      "[59]\ttest-logloss:0.31128\n",
      "[60]\ttest-logloss:0.31044\n",
      "[61]\ttest-logloss:0.30999\n",
      "[62]\ttest-logloss:0.30944\n",
      "[63]\ttest-logloss:0.30827\n",
      "[64]\ttest-logloss:0.30736\n",
      "[65]\ttest-logloss:0.30693\n",
      "[66]\ttest-logloss:0.30649\n",
      "[67]\ttest-logloss:0.30616\n",
      "[68]\ttest-logloss:0.30597\n",
      "[69]\ttest-logloss:0.30545\n",
      "[70]\ttest-logloss:0.30467\n",
      "[71]\ttest-logloss:0.30369\n",
      "[72]\ttest-logloss:0.30301\n",
      "[73]\ttest-logloss:0.30259\n",
      "[74]\ttest-logloss:0.30229\n",
      "[75]\ttest-logloss:0.30223\n",
      "[76]\ttest-logloss:0.30199\n",
      "[77]\ttest-logloss:0.30188\n",
      "[78]\ttest-logloss:0.30151\n",
      "[79]\ttest-logloss:0.30069\n",
      "[80]\ttest-logloss:0.30005\n",
      "[81]\ttest-logloss:0.29910\n",
      "[82]\ttest-logloss:0.29877\n",
      "[83]\ttest-logloss:0.29855\n",
      "[84]\ttest-logloss:0.29804\n",
      "[85]\ttest-logloss:0.29721\n",
      "[86]\ttest-logloss:0.29652\n",
      "[87]\ttest-logloss:0.29600\n",
      "[88]\ttest-logloss:0.29578\n",
      "[89]\ttest-logloss:0.29525\n",
      "[90]\ttest-logloss:0.29459\n",
      "[91]\ttest-logloss:0.29382\n",
      "[92]\ttest-logloss:0.29341\n",
      "[93]\ttest-logloss:0.29312\n",
      "[94]\ttest-logloss:0.29239\n",
      "[95]\ttest-logloss:0.29204\n",
      "[96]\ttest-logloss:0.29158\n",
      "[97]\ttest-logloss:0.29160\n",
      "[98]\ttest-logloss:0.29166\n",
      "[99]\ttest-logloss:0.29120\n",
      "[100]\ttest-logloss:0.29090\n",
      "[101]\ttest-logloss:0.29058\n",
      "[102]\ttest-logloss:0.28972\n",
      "[103]\ttest-logloss:0.28957\n",
      "[104]\ttest-logloss:0.28980\n",
      "[105]\ttest-logloss:0.28972\n",
      "[106]\ttest-logloss:0.28954\n",
      "[107]\ttest-logloss:0.28926\n",
      "[108]\ttest-logloss:0.28909\n",
      "[109]\ttest-logloss:0.28918\n",
      "[110]\ttest-logloss:0.28862\n",
      "[111]\ttest-logloss:0.28799\n",
      "[112]\ttest-logloss:0.28761\n",
      "[113]\ttest-logloss:0.28734\n",
      "[114]\ttest-logloss:0.28697\n",
      "[115]\ttest-logloss:0.28686\n",
      "[116]\ttest-logloss:0.28668\n",
      "[117]\ttest-logloss:0.28645\n",
      "[118]\ttest-logloss:0.28610\n",
      "[119]\ttest-logloss:0.28571\n",
      "[120]\ttest-logloss:0.28560\n",
      "[121]\ttest-logloss:0.28539\n",
      "[122]\ttest-logloss:0.28520\n",
      "[123]\ttest-logloss:0.28492\n",
      "[124]\ttest-logloss:0.28484\n",
      "[125]\ttest-logloss:0.28449\n",
      "[126]\ttest-logloss:0.28395\n",
      "[127]\ttest-logloss:0.28394\n",
      "[128]\ttest-logloss:0.28339\n",
      "[129]\ttest-logloss:0.28319\n",
      "[130]\ttest-logloss:0.28283\n",
      "[131]\ttest-logloss:0.28250\n",
      "[132]\ttest-logloss:0.28210\n",
      "[133]\ttest-logloss:0.28176\n",
      "[134]\ttest-logloss:0.28178\n",
      "[135]\ttest-logloss:0.28194\n",
      "[136]\ttest-logloss:0.28166\n",
      "[137]\ttest-logloss:0.28161\n",
      "[138]\ttest-logloss:0.28142\n",
      "[139]\ttest-logloss:0.28105\n",
      "[140]\ttest-logloss:0.28072\n",
      "[141]\ttest-logloss:0.28060\n",
      "[142]\ttest-logloss:0.28040\n",
      "[143]\ttest-logloss:0.28042\n",
      "[144]\ttest-logloss:0.28024\n",
      "[145]\ttest-logloss:0.28009\n",
      "[146]\ttest-logloss:0.28001\n",
      "[147]\ttest-logloss:0.27979\n",
      "[148]\ttest-logloss:0.27975\n",
      "[149]\ttest-logloss:0.27947\n",
      "[150]\ttest-logloss:0.27901\n",
      "[151]\ttest-logloss:0.27853\n",
      "[152]\ttest-logloss:0.27830\n",
      "[153]\ttest-logloss:0.27823\n",
      "[154]\ttest-logloss:0.27796\n",
      "[155]\ttest-logloss:0.27780\n",
      "[156]\ttest-logloss:0.27753\n",
      "[157]\ttest-logloss:0.27757\n",
      "[158]\ttest-logloss:0.27753\n",
      "[159]\ttest-logloss:0.27702\n",
      "[160]\ttest-logloss:0.27679\n",
      "[161]\ttest-logloss:0.27678\n",
      "[162]\ttest-logloss:0.27666\n",
      "[163]\ttest-logloss:0.27668\n",
      "[164]\ttest-logloss:0.27657\n",
      "[165]\ttest-logloss:0.27650\n",
      "[166]\ttest-logloss:0.27618\n",
      "[167]\ttest-logloss:0.27586\n",
      "[168]\ttest-logloss:0.27575\n",
      "[169]\ttest-logloss:0.27547\n",
      "[170]\ttest-logloss:0.27532\n",
      "[171]\ttest-logloss:0.27523\n",
      "[172]\ttest-logloss:0.27523\n",
      "[173]\ttest-logloss:0.27494\n",
      "[174]\ttest-logloss:0.27496\n",
      "[175]\ttest-logloss:0.27499\n",
      "[176]\ttest-logloss:0.27497\n",
      "[177]\ttest-logloss:0.27486\n",
      "[178]\ttest-logloss:0.27469\n",
      "[179]\ttest-logloss:0.27475\n",
      "[180]\ttest-logloss:0.27442\n",
      "[181]\ttest-logloss:0.27424\n",
      "[182]\ttest-logloss:0.27402\n",
      "[183]\ttest-logloss:0.27404\n",
      "[184]\ttest-logloss:0.27392\n",
      "[185]\ttest-logloss:0.27341\n",
      "[186]\ttest-logloss:0.27349\n",
      "[187]\ttest-logloss:0.27346\n",
      "[188]\ttest-logloss:0.27343\n",
      "[189]\ttest-logloss:0.27349\n",
      "[190]\ttest-logloss:0.27333\n",
      "[191]\ttest-logloss:0.27285\n",
      "[192]\ttest-logloss:0.27297\n",
      "[193]\ttest-logloss:0.27289\n",
      "[194]\ttest-logloss:0.27243\n",
      "[195]\ttest-logloss:0.27222\n",
      "[196]\ttest-logloss:0.27212\n",
      "[197]\ttest-logloss:0.27199\n",
      "[198]\ttest-logloss:0.27202\n",
      "[199]\ttest-logloss:0.27176\n",
      "[200]\ttest-logloss:0.27183\n",
      "[201]\ttest-logloss:0.27177\n",
      "[202]\ttest-logloss:0.27178\n",
      "[203]\ttest-logloss:0.27181\n",
      "[204]\ttest-logloss:0.27166\n",
      "[205]\ttest-logloss:0.27167\n",
      "[206]\ttest-logloss:0.27177\n",
      "[207]\ttest-logloss:0.27134\n",
      "[208]\ttest-logloss:0.27128\n",
      "[209]\ttest-logloss:0.27099\n",
      "[210]\ttest-logloss:0.27102\n",
      "[211]\ttest-logloss:0.27106\n",
      "[212]\ttest-logloss:0.27044\n",
      "[213]\ttest-logloss:0.27031\n",
      "[214]\ttest-logloss:0.27022\n",
      "[215]\ttest-logloss:0.27025\n",
      "[216]\ttest-logloss:0.27046\n",
      "[217]\ttest-logloss:0.27040\n",
      "[218]\ttest-logloss:0.27016\n",
      "[219]\ttest-logloss:0.26996\n",
      "[220]\ttest-logloss:0.26964\n",
      "[221]\ttest-logloss:0.26956\n",
      "[222]\ttest-logloss:0.26966\n",
      "[223]\ttest-logloss:0.26945\n",
      "[224]\ttest-logloss:0.26941\n",
      "[225]\ttest-logloss:0.26923\n",
      "[226]\ttest-logloss:0.26910\n",
      "[227]\ttest-logloss:0.26888\n",
      "[228]\ttest-logloss:0.26873\n",
      "[229]\ttest-logloss:0.26875\n",
      "[230]\ttest-logloss:0.26882\n",
      "[231]\ttest-logloss:0.26873\n",
      "[232]\ttest-logloss:0.26840\n",
      "[233]\ttest-logloss:0.26825\n",
      "[234]\ttest-logloss:0.26802\n",
      "[235]\ttest-logloss:0.26778\n",
      "[236]\ttest-logloss:0.26793\n",
      "[237]\ttest-logloss:0.26769\n",
      "[238]\ttest-logloss:0.26778\n",
      "[239]\ttest-logloss:0.26775\n",
      "[240]\ttest-logloss:0.26764\n",
      "[241]\ttest-logloss:0.26764\n",
      "[242]\ttest-logloss:0.26750\n",
      "[243]\ttest-logloss:0.26745\n",
      "[244]\ttest-logloss:0.26741\n",
      "[245]\ttest-logloss:0.26740\n",
      "[246]\ttest-logloss:0.26743\n",
      "[247]\ttest-logloss:0.26744\n",
      "[248]\ttest-logloss:0.26754\n",
      "[249]\ttest-logloss:0.26753\n",
      "[250]\ttest-logloss:0.26755\n",
      "[251]\ttest-logloss:0.26752\n",
      "[252]\ttest-logloss:0.26761\n",
      "[253]\ttest-logloss:0.26752\n",
      "[254]\ttest-logloss:0.26758\n",
      "[255]\ttest-logloss:0.26757\n",
      "Accuracy on entire thing: 0.8895939086294417\n",
      "Accuracy on balanced part: 0.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train a logistic regression model using XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {'objective': 'binary:logistic'}\n",
    "xgb_bow = xgb.train(params, dtrain, num_boost_round=1000, early_stopping_rounds=10, evals=[(dtest, 'test')])\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = xgb_bow.predict(dtest)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy on entire thing:', accuracy_score(y_test, y_pred.round()))\n",
    "\n",
    "dbalance = xgb.DMatrix(balanced_X_test,label = balanced_y_test)\n",
    "\n",
    "# Predict on the balanced test set\n",
    "y_pred_balanced = xgb_bow.predict(dbalance)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print('Accuracy on balanced part:', accuracy_score(balanced_y_test, y_pred_balanced.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          i have bought sever of the vital can dog food...\n",
       "1          product arriv label as jumbo salt peanut the ...\n",
       "2          this is a confect that has been around a few ...\n",
       "3          if you are look for the secret ingredi in rob...\n",
       "4          great taffi at a great price there was a wide...\n",
       "                                ...                        \n",
       "393912     great for sesam chicken this is a good if not...\n",
       "393913     im disappoint with the flavor the chocol note...\n",
       "393914     these star are small so you can give 10-15 of...\n",
       "393915     these are the best treat for train and reward...\n",
       "393916     i am veri satisfi product is as advertis i us...\n",
       "Name: Text, Length: 393917, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1458 candidates, totalling 4374 fits\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.5; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.5; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.5; total time=  17.7s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.75; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.75; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=0.75; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=0.1, subsample=0.5; total time=  18.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6136\\479534940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Perform grid search using cross-validation on the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1488\u001b[0m             )\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, random_state=42, stratify=y_trainval)\n",
    "\n",
    "# Define a grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [5, 7],\n",
    "    'n_estimators': [200],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier object\n",
    "xgb = XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Perform grid search using cross-validation on the training set\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=3, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "for i in range(len(grid_search.cv_results_['params'])):\n",
    "    print(\"Params:\", grid_search.cv_results_['params'][i])\n",
    "    print(\"Mean test score:\", grid_search.cv_results_['mean_test_score'][i])\n",
    "    print(\"Standard deviation of test score:\", grid_search.cv_results_['std_test_score'][i])\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "# Evaluate the best hyperparameters on the validation set\n",
    "best_xgb_bow = grid_search.best_estimator_\n",
    "y_val_pred = best_xgb_bow.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Test the final model on the test set\n",
    "y_test_pred = best_xgb_bow.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best hyperparameters and their score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF with BOOSTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393917, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "final_tf = cleaned_data['Text']\n",
    "tf_idf = TfidfVectorizer(max_features=1000)\n",
    "tf_data = tf_idf.fit_transform(final_tf)\n",
    "tf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf_data.toarray() # turning sparse matrix into dense matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.83%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, y, train_size = .7, test_size=0.01, random_state=42)\n",
    "\n",
    "# Calculate frequency of each class in the training set\n",
    "class_freq = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Split testing set into two parts, one for each class\n",
    "pos_idx = np.where(y_test == 1)[0]\n",
    "neg_idx = np.where(y_test == 0)[0]\n",
    "\n",
    "pos_test_set = X_test[pos_idx]\n",
    "neg_test_set = X_test[neg_idx]\n",
    "\n",
    "# Combine the two testing sets to create a balanced testing set\n",
    "min_len = min(pos_test_set.shape[0], neg_test_set.shape[0])\n",
    "\n",
    "balanced_X_test = np.concatenate((pos_test_set[:min_len], neg_test_set[:min_len]))\n",
    "balanced_y_test = np.concatenate((np.ones(min_len), np.zeros(min_len)))\n",
    "\n",
    "# Shuffle the examples in the balanced testing set\n",
    "shuffle_idx = np.random.permutation(len(balanced_y_test))\n",
    "balanced_X_test = balanced_X_test[shuffle_idx]\n",
    "balanced_y_test = balanced_y_test[shuffle_idx]\n",
    "\n",
    "# Define XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Train XGBoost classifier on training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate XGBoost classifier on test data\n",
    "accuracy = xgb_clf.score(balanced_X_test, balanced_y_test)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "#accuracy 74.83% on the initial run for a balanced panel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample: 89.11%\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, y, test_size=0.3, random_state=42)\n",
    "accuracy = xgb_clf.score (X_test,y_test)\n",
    "print('Accuracy on random sample: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "#89% accuracy on random sample "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(temp, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, random_state=42, stratify=y_trainval)\n",
    "\n",
    "# Define a grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    #'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    #'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    #'gamma': [0, 0.1, 0.2],\n",
    "    #'reg_alpha': [0, 0.1, 0.5],\n",
    "    #'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier object\n",
    "xgb = XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Perform grid search using cross-validation on the training set\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best hyperparameters on the validation set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_val_pred = best_xgb.predict(X_val)\n",
    "val_acc = best_xgb.score(y_val, y_val_pred)\n",
    "\n",
    "# Test the final model on the test set\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "test_acc = best_xgb.score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best hyperparameters and their score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "#87.4% accuracy w 0.75 colsample by tree, max depth o f7 and 200 estimators, subsample 1, gamma 0, alpha 0, lambda 1\n",
    "#takes an entire hour \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.75, 'max_depth': 7, 'n_estimators': 200}\n",
      "Best score: 0.8739259391682477\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best hyperparameters on the validation set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_val_pred = best_xgb.predict(X_val)\n",
    "val_acc = best_xgb.score(y_val, y_val_pred)\n",
    "\n",
    "# Test the final model on the test set\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "test_acc = best_xgb.score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best hyperparameters and their score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8387470997679815\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, y, train_size = .7, test_size=0.01, random_state=42)\n",
    "\n",
    "# Calculate frequency of each class in the training set\n",
    "class_freq = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Split testing set into two parts, one for each class\n",
    "pos_idx = np.where(y_test == 1)[0]\n",
    "neg_idx = np.where(y_test == 0)[0]\n",
    "\n",
    "pos_test_set = X_test[pos_idx]\n",
    "neg_test_set = X_test[neg_idx]\n",
    "\n",
    "# Combine the two testing sets to create a balanced testing set\n",
    "min_len = min(pos_test_set.shape[0], neg_test_set.shape[0])\n",
    "\n",
    "balanced_X_test = np.concatenate((pos_test_set[:min_len], neg_test_set[:min_len]))\n",
    "balanced_y_test = np.concatenate((np.ones(min_len), np.zeros(min_len)))\n",
    "\n",
    "# Shuffle the examples in the balanced testing set\n",
    "shuffle_idx = np.random.permutation(len(balanced_y_test))\n",
    "balanced_X_test = balanced_X_test[shuffle_idx]\n",
    "balanced_y_test = balanced_y_test[shuffle_idx]\n",
    "\n",
    "# Test the model on the testing dataset\n",
    "y_pred = best_xgb.predict(balanced_X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = np.mean(y_pred == balanced_y_test)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample: 91.19%\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, y, test_size=0.3, random_state=42)\n",
    "accuracy = best_xgb.score (X_test,y_test)\n",
    "print('Accuracy on random sample: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "#91.19% accuracy on random sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Time taken: 0.0\n",
      "[' i do not know']\n",
      "<class 'numpy.ndarray'>\n",
      "Probability of a positive review is 0.2703675627708435\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"I do not know\"]\n",
    "clean_sentence = clean_data(sentence)\n",
    "print(clean_sentence)\n",
    "sparse = tf_idf.transform(clean_sentence)\n",
    "\n",
    "sparse = sparse.toarray()\n",
    "\n",
    "prob = best_xgb.predict_proba(sparse)\n",
    "print(type(prob))\n",
    "print(f'Probability of a positive review is {prob[0][1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training W2V Model\n",
    "sentences = [gensim.utils.simple_preprocess(text) for text in cleaned_data['Text']]\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "#takes around a minute or so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text encoding\n",
    "def encode_text(text):\n",
    "    words = gensim.utils.simple_preprocess(text)\n",
    "    vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(vecs) > 0:\n",
    "        return np.mean(vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "cleaned_data['encoded_text'] = cleaned_data['Text'].apply(encode_text)\n",
    "\n",
    "#takes about a minute or so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8651502843216897\n"
     ]
    }
   ],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data['encoded_text'], y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Model\n",
    "xg_train = xgb.DMatrix(np.array(list(X_train)), label=y_train)\n",
    "xg_test = xgb.DMatrix(np.array(list(X_test)), label=y_test)\n",
    "param = {'max_depth': 7, 'eta': 0.15, 'objective': 'binary:logistic'}\n",
    "xgb_w2v = xgb.train(param, xg_train, num_boost_round=100)\n",
    "\n",
    "\n",
    "#model eval\n",
    "y_pred = xgb_w2v.predict(xg_test)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "#86.5% accuracy wahhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please reshape the input data into 2-dimensional matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32620\\3424147929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxg_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[0;32m    744\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;34m'''Dispatch data for DMatrix.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_cudf_ser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0m_check_data_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_check_data_shape\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please reshape the input data into 2-dimensional matrix.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please reshape the input data into 2-dimensional matrix."
     ]
    }
   ],
   "source": [
    "xg_test = xgb.DMatrix(np.array(list(test_df['Text'])), label=test_df['Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319409    [0.2580548, -0.095952146, 0.22290576, 0.094422...\n",
       "50116     [0.2708252, -0.15965064, 0.28282544, 0.1543303...\n",
       "324296    [0.17068242, 0.23078741, 0.23908558, -0.323772...\n",
       "41693     [0.5475419, -0.2107918, -0.026301779, 0.034036...\n",
       "27294     [0.26602906, -0.08991946, 0.060180604, 0.06457...\n",
       "                                ...                        \n",
       "108307    [0.20781834, 0.23939013, 0.36853963, -0.145921...\n",
       "371197    [0.4338081, 0.040465835, 0.14736585, 0.1748648...\n",
       "47798     [0.19281393, 0.20094402, 0.22531913, 0.2747895...\n",
       "82089     [0.28207597, 0.08878692, 0.3718162, -0.0342229...\n",
       "21047     [-0.06931823, 0.20355266, -0.020673422, 0.1815...\n",
       "Name: encoded_text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['encoded_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2000, 393917]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32620\\3773244109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#try 50/50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Define XGBoost classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxgb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2439\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2441\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m     return list(\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1597\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \"\"\"\n\u001b[1;32m-> 1599\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2000, 393917]"
     ]
    }
   ],
   "source": [
    "#try 50/50\n",
    "X_train, X_test, y_train, y_test = train_test_split(test_df['encoded_text'], test_df['Score'], test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Train XGBoost classifier on training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate XGBoost classifier on test data\n",
    "accuracy = xgb_clf.score(X_test, y_test)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Value: 4 Accuracy: 0.8505449499052261\n",
      "Param Value: 5 Accuracy: 0.8539720417005144\n",
      "Param Value: 6 Accuracy: 0.8564683184402925\n",
      "Param Value: 7 Accuracy: 0.8577291497427566\n",
      "Param Value: 8 Accuracy: 0.8597515569997293\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST\n",
    "\n",
    "for param_value in [4,5,6,7,8]: \n",
    "    #Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cleaned_data['encoded_text'], y, test_size=0.3, random_state=42)\n",
    "\n",
    "    #Model\n",
    "    xg_train = xgb.DMatrix(np.array(list(X_train)), label=y_train)\n",
    "    xg_test = xgb.DMatrix(np.array(list(X_test)), label=y_test)\n",
    "    param = {'max_depth': param_value, 'eta': 0.15, 'objective': 'binary:logistic'}\n",
    "    model = xgb.train(param, xg_train, num_boost_round=100)\n",
    "\n",
    "\n",
    "    #model eval\n",
    "    y_pred = model.predict(xg_test)\n",
    "    y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    print(f'Param Value: {param_value} Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "#as this model gets more complex, we actually see it get better.... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8001455456268616\n"
     ]
    }
   ],
   "source": [
    "#model eval for 10-D W2V embeddings\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data['encoded_text_10'], y, test_size=0.3, random_state=42)\n",
    "#Model\n",
    "xg_train = xgb.DMatrix(np.array(list(X_train)), label=y_train)\n",
    "xg_test = xgb.DMatrix(np.array(list(X_test)), label=y_test)\n",
    "param = {'max_depth': 6, 'eta': 0.3, 'objective': 'binary:logistic','lambda': 1}\n",
    "model = xgb.train(param, xg_train)\n",
    "\n",
    "y_pred = model.predict(xg_test)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "#default params, depth 6 eta 0.3, lambda = 1\n",
    "#vector size 10 \n",
    "#80% accurate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 3.05501968e-01, -9.62868929e-02,  3.21318805e-01, -2.11178456e-02,\n",
       "               4.50601093e-02, -2.59613663e-01, -8.91744047e-02, -1.06418058e-01,\n",
       "              -4.09026854e-02,  2.54805923e-01, -9.31983292e-02, -1.80127602e-02,\n",
       "              -2.19290316e-01,  5.22617340e-01,  8.09774026e-02,  3.86451989e-01,\n",
       "               1.11205347e-01,  1.63718328e-01,  3.55907828e-01, -5.27243614e-02,\n",
       "              -2.08552629e-01, -5.06018877e-01, -5.92609942e-02,  1.06266290e-01,\n",
       "              -5.21547683e-02, -7.90234134e-02, -1.75521359e-01,  4.61480886e-01,\n",
       "              -3.20887506e-01, -7.33172847e-03, -5.59408128e-01, -1.92320675e-01,\n",
       "              -3.20619553e-01,  5.95456481e-01,  1.90435514e-01,  1.41120061e-01,\n",
       "              -1.68033279e-02, -1.34337038e-01,  3.44929814e-01,  3.95025939e-01,\n",
       "               2.07313076e-01, -1.77934989e-01, -1.59556866e-01,  6.82880804e-02,\n",
       "               1.68053225e-01, -3.42262387e-01,  1.01048037e-01,  1.70407668e-01,\n",
       "              -1.78010881e-01,  2.30989963e-01,  1.79284990e-01,  5.00636876e-01,\n",
       "              -4.02405374e-02,  7.13035762e-02,  6.53586388e-02, -3.13414216e-01,\n",
       "               1.54885665e-01, -4.52567518e-01,  1.49982825e-01,  6.98273629e-02,\n",
       "              -6.62306622e-02,  7.20934033e-01, -4.37591255e-01, -1.72886014e-01,\n",
       "              -2.92373538e-01, -8.50026011e-02,  3.66748482e-01,  4.74698812e-01,\n",
       "               4.58135992e-01,  2.11858183e-01,  4.86068100e-01, -1.64561719e-01,\n",
       "              -6.21900894e-02, -3.64620835e-01,  1.52215004e-01,  2.26097196e-01,\n",
       "               4.50671390e-02, -7.73974881e-02,  4.12544496e-02,  1.52191550e-01,\n",
       "              -2.42306024e-01, -3.72938037e-01,  3.54772247e-02, -2.39437118e-01,\n",
       "               5.81825495e-01,  1.34380847e-01, -2.63817906e-01,  4.92121130e-01,\n",
       "               1.93986133e-01,  2.17253193e-01,  1.32685110e-01, -1.53474033e-01,\n",
       "              -9.82161835e-02,  2.75060028e-01, -5.73155470e-02, -4.22840752e-02,\n",
       "              -9.63868424e-02,  1.37824550e-01, -3.05458993e-01,  2.28853777e-01,\n",
       "              -1.91935096e-02,  4.44964379e-01, -5.37620485e-01,  1.66087940e-01,\n",
       "              -6.07511163e-01,  5.50249591e-02, -2.03957260e-02,  9.57830846e-02,\n",
       "              -1.18856132e-01,  3.49263474e-02, -1.57971248e-01, -2.39732280e-01,\n",
       "               2.21621066e-01,  5.07089734e-01,  1.58215180e-01,  2.06629410e-01,\n",
       "               1.27506256e-01, -1.89867355e-02,  7.36057311e-02, -1.47794962e-01,\n",
       "               6.59851581e-02,  8.65427777e-02, -3.75511259e-01, -9.30671692e-02,\n",
       "               1.56453148e-01,  6.20947242e-01, -1.55413285e-01, -1.07014485e-01,\n",
       "               3.87388229e-01, -2.20547572e-01, -5.14593460e-02, -6.36567771e-02,\n",
       "               6.04805231e-01,  4.30751685e-03, -1.00586362e-01,  2.09732056e-02,\n",
       "               1.87592119e-01,  4.35623437e-01, -4.67937961e-02,  3.86811197e-01,\n",
       "              -1.57684520e-01, -1.51320007e-02, -3.96847606e-01,  3.30482274e-01,\n",
       "              -3.86936702e-02,  4.69709784e-02, -2.81894356e-01, -5.50304830e-01,\n",
       "               1.05087951e-01, -1.00163619e-04,  1.18918642e-01, -9.94616523e-02,\n",
       "              -4.73026901e-01,  3.76376770e-02,  1.61878899e-01,  3.39135349e-01,\n",
       "               2.14878947e-01,  8.23376551e-02, -8.21699426e-02, -6.13116063e-02,\n",
       "              -2.43802935e-01, -1.13896124e-01,  2.40499184e-01, -3.84713501e-01,\n",
       "               2.24327192e-01,  2.04746142e-01, -3.02417487e-01,  2.73985535e-01,\n",
       "              -2.02820584e-01, -4.57779467e-02,  1.80040166e-01, -1.12349287e-01,\n",
       "              -1.97986245e-01,  1.33788615e-01,  2.51302689e-01,  1.20275632e-01,\n",
       "              -3.92221868e-01,  1.66414827e-01,  5.99368215e-02, -1.04847364e-01,\n",
       "               1.98856860e-01, -1.47937832e-03,  1.54286712e-01, -1.23904973e-01,\n",
       "               8.16289186e-02, -7.39455223e-01,  7.72832260e-02,  7.64121041e-02,\n",
       "               1.36815393e-02,  5.63053228e-02,  2.03826092e-02, -9.83412191e-02,\n",
       "               9.93000343e-02, -5.47013640e-01, -2.44926721e-01, -2.56222844e-01,\n",
       "               8.51714835e-02,  7.96499997e-02, -2.14292184e-01,  3.04416176e-02,\n",
       "               7.49843493e-02,  1.23947076e-01,  3.50676000e-01,  4.42434192e-01,\n",
       "               9.38362107e-02, -2.80725062e-01,  9.15848389e-02,  6.06524825e-01,\n",
       "              -1.61793996e-02,  1.38631180e-01,  3.56150307e-02, -5.09009302e-01,\n",
       "              -9.99497157e-03,  2.84462273e-01,  1.01970643e-01, -2.52955884e-01,\n",
       "               5.37487686e-01,  4.41283673e-01, -1.59216821e-01, -2.73012698e-01,\n",
       "               1.16285030e-02,  8.73410255e-02, -5.92670381e-01, -3.21509689e-01,\n",
       "               7.36820400e-02, -4.57574725e-01, -1.30102664e-01,  5.49590439e-02,\n",
       "               3.21330249e-01,  1.01495661e-01, -1.20186888e-01,  2.66821659e-03,\n",
       "               4.55722548e-02, -2.10631132e-01, -1.55264124e-01,  4.42340881e-01,\n",
       "              -2.35454723e-01,  5.09091973e-01,  2.59060174e-01,  1.07545123e-01,\n",
       "              -1.31737351e-01, -1.98427364e-01, -1.85993746e-01, -1.66151207e-02,\n",
       "              -9.09996033e-02, -1.04430644e-03,  3.19880433e-02, -1.31980767e-02,\n",
       "               2.66298473e-01, -2.47882277e-01, -1.35582983e-01, -4.29481268e-02,\n",
       "               3.29935461e-01, -8.60354826e-02, -1.94105282e-01, -2.35226631e-01,\n",
       "               1.76080212e-01, -1.01980090e-01, -1.19363174e-01, -2.40213238e-02,\n",
       "              -1.12952389e-01, -3.63962352e-01, -1.46417961e-01, -2.52919674e-01,\n",
       "               1.53090745e-01,  8.42890982e-03,  3.22605550e-01,  1.08999483e-01,\n",
       "              -5.42848527e-01,  8.57193545e-02, -5.19113056e-02, -3.72374177e-01,\n",
       "              -1.62447263e-02,  1.76830664e-02,  5.24841547e-01,  3.05889100e-01,\n",
       "               7.77349412e-01, -8.54591429e-02,  4.06067856e-02,  1.50630087e-01,\n",
       "              -3.22563648e-01,  9.88110527e-02,  3.58377963e-01,  1.75091609e-01,\n",
       "               5.22925844e-03, -3.67615134e-01,  2.16949694e-02,  1.43319786e-01,\n",
       "               1.97496936e-02, -5.36728017e-02,  1.23509817e-01, -1.53881228e-02,\n",
       "              -2.25793898e-01,  4.57303189e-02,  1.03860676e-01, -5.81000820e-02,\n",
       "              -1.46780282e-01,  2.67641861e-02,  2.25341499e-01,  5.07351816e-01],\n",
       "             dtype=float32)                                                       ,\n",
       "       array([ 0.28284666, -0.3331764 ,  0.49554756,  0.02516178,  0.35174984,\n",
       "              -0.49224344,  0.16439925,  1.1219229 ,  0.44761527,  0.36362767,\n",
       "              -0.3161578 ,  0.2339345 , -0.11069092,  0.3514045 , -0.08573508,\n",
       "              -0.11341973, -0.24232948,  0.432405  ,  0.04581389, -0.31482533,\n",
       "              -0.17451173, -0.05513242,  0.02307629, -0.3510447 , -0.22251937,\n",
       "               0.25443935, -0.09209504,  0.21633178, -0.0173782 , -0.43386343,\n",
       "              -0.7246396 ,  0.15614104,  0.43571004,  0.57548445, -0.30143926,\n",
       "               0.06555641, -0.39384544, -0.31964955,  0.55456895, -0.00248095,\n",
       "              -0.06289621, -0.16231012, -0.07096951,  0.10169916,  0.44339252,\n",
       "              -0.31839514,  0.19714111, -0.10782088, -0.30059522,  0.2135257 ,\n",
       "               0.38063645,  0.14831257, -0.17748062,  0.36089095,  0.14832677,\n",
       "              -0.17243339,  0.19819537, -0.26905996,  0.30381137, -0.48912367,\n",
       "               0.095283  ,  0.44255474, -0.27501017,  0.43884245,  0.11151771,\n",
       "               0.33797473, -0.09033217,  0.32754374, -0.29354247,  0.46007064,\n",
       "               0.4425751 , -0.12183031,  0.240121  , -0.17959526,  0.23686312,\n",
       "               0.03050192, -0.06072801, -0.06986387,  0.06117304, -0.11531313,\n",
       "              -0.4707544 , -0.32908767,  0.06314846, -0.4009315 ,  0.27659294,\n",
       "               0.04636008, -0.06233009,  0.27354446, -0.5052405 , -0.02273086,\n",
       "               0.5998345 , -0.25427237, -0.22649892,  0.63493377, -0.13542795,\n",
       "              -0.58370614,  0.09817596,  0.03744763, -0.42874622, -0.04349094,\n",
       "              -0.09243273, -0.04093736, -0.37553903, -0.23815744, -0.4838202 ,\n",
       "               0.5418727 , -0.18829522, -0.2659628 , -0.15532298, -0.18688595,\n",
       "               0.00460396, -0.44320905,  0.08731139,  0.1239253 ,  0.7750068 ,\n",
       "               0.1541471 ,  0.10318163, -0.13591278, -0.26850578, -0.27268973,\n",
       "              -0.07246482, -0.09176011,  0.10226798, -0.5119655 , -0.20849384,\n",
       "               0.02917518, -0.3573336 ,  0.11726422,  0.23256803,  0.02320718,\n",
       "              -0.21409388, -0.1218726 ,  0.5488965 , -0.22434445, -0.12755974,\n",
       "               0.16803674, -0.10269791,  0.24866173, -0.08450416,  0.4226987 ,\n",
       "              -0.44651654,  0.3278629 , -0.34424648, -0.2262822 , -0.29092103,\n",
       "               0.01182705,  0.11102413, -0.16752014, -0.6370982 ,  0.07402   ,\n",
       "              -0.10013618, -0.14358108, -0.2050466 ,  0.0144727 ,  0.09048396,\n",
       "              -0.19792394,  0.15405461, -0.47446156,  0.42518866,  0.35275528,\n",
       "              -0.16746585, -0.04721231,  0.25367135, -0.68548614, -0.06480925,\n",
       "               0.35408232,  0.22120303,  0.00260779, -0.48824018,  0.14990306,\n",
       "               0.44364864, -0.27287665,  0.25111505,  0.5782889 , -0.07487797,\n",
       "               0.03536811, -0.09063758, -0.02166341, -0.27532727, -0.07688478,\n",
       "               0.6010902 , -0.07372586,  0.32074267,  0.15952592,  0.16411565,\n",
       "              -0.3147611 ,  0.01131392,  0.27835405, -0.4095107 , -0.15760112,\n",
       "               0.15661585, -0.1617244 , -0.35023603, -0.45198423,  0.16869539,\n",
       "              -0.05683014,  0.55830055,  0.27462828, -0.58395994, -0.06248613,\n",
       "               0.30188975, -0.17856577,  0.3896374 ,  0.0935263 ,  0.38478148,\n",
       "              -0.5831093 ,  0.46382156,  0.7790193 ,  0.06058925, -0.5909283 ,\n",
       "               0.02526429, -0.23366877, -0.2671077 ,  0.52423406,  0.02868819,\n",
       "               0.05222693,  0.25077888,  0.16663332,  0.46866417, -0.07954149,\n",
       "              -0.39404523,  0.02942824, -0.49289834, -0.2886207 , -0.13343202,\n",
       "              -0.2706677 ,  0.19843188, -0.535412  , -0.08835865,  0.35828826,\n",
       "               0.05434147,  0.16186461, -0.01454945,  0.02992638, -0.12340489,\n",
       "               0.31604803, -0.6290896 ,  0.5511331 ,  0.01328639,  0.11857821,\n",
       "               0.1253264 , -0.20522591, -0.3009335 , -0.35188526,  0.3793815 ,\n",
       "               0.16883798, -0.24749346, -0.49912885, -0.00863455, -0.18473871,\n",
       "              -0.26586002,  0.27219206,  0.183701  , -0.1219606 , -0.18272164,\n",
       "              -0.6952164 ,  0.10719631,  0.04235753, -0.41537684,  0.19078434,\n",
       "               0.2943175 , -0.19150662, -0.48872945, -0.49482003, -0.17534664,\n",
       "               0.00723306, -0.05563249, -0.391047  , -0.08110794, -0.39018124,\n",
       "              -0.06470282,  0.10334532,  0.11212372, -0.16595456,  0.6331483 ,\n",
       "               0.01981989,  0.37638924,  0.04155275, -0.09812114,  0.01910742,\n",
       "              -0.8496962 , -0.40712592,  0.11340282,  0.072946  , -0.4833419 ,\n",
       "              -0.32917678,  0.2746087 ,  0.04207007,  0.12520637,  0.21396393,\n",
       "               0.07223061, -0.3132716 ,  0.30956146, -0.09352239,  0.11693727,\n",
       "              -0.17491175,  0.11451155, -0.3732949 , -0.2966105 ,  0.2532852 ],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([ 0.06795633,  0.04646062,  0.3303152 ,  0.04571411,  0.13252737,\n",
       "              -0.1927887 , -0.01165034,  0.00903038, -0.07785785,  0.17536242,\n",
       "              -0.18482749,  0.46090037, -0.14584023,  0.4071559 ,  0.0050736 ,\n",
       "               0.02400552, -0.00833702,  0.10099416,  0.05211646,  0.21427156,\n",
       "              -0.01376576,  0.04218   ,  0.06238543,  0.08720186, -0.2973517 ,\n",
       "              -0.07909937, -0.04916768,  0.564636  ,  0.22952558, -0.04725487,\n",
       "              -0.5830263 , -0.02260858, -0.02766638,  0.22010662, -0.148174  ,\n",
       "               0.17301714, -0.3017124 , -0.04930101,  0.3395582 ,  0.34171134,\n",
       "               0.3008006 , -0.37869915, -0.58069456,  0.1288559 ,  0.15136991,\n",
       "              -0.24100435,  0.0045239 , -0.12676223, -0.5587984 ,  0.1926107 ,\n",
       "               0.46716207,  0.34465823, -0.40769866, -0.10830086, -0.00848562,\n",
       "              -0.31717673,  0.26987603, -0.10683875,  0.3523461 , -0.12776303,\n",
       "              -0.10494162,  0.21031947, -0.16524082, -0.13599466,  0.2218743 ,\n",
       "              -0.01067588,  0.2089232 ,  0.38048202, -0.0167549 ,  0.19606142,\n",
       "               0.39361182, -0.28182265, -0.18338719, -0.58358794,  0.06968036,\n",
       "              -0.21732362,  0.02071412, -0.12253637,  0.03773845,  0.15741585,\n",
       "              -0.41076204, -0.0688458 , -0.13409914, -0.23123327,  0.06751645,\n",
       "              -0.03948042,  0.00958733,  0.04651968,  0.01585233, -0.13697924,\n",
       "              -0.29345277,  0.05452122, -0.17901354,  0.14676893, -0.01907644,\n",
       "              -0.08288669, -0.01374382,  0.27798238, -0.3725982 , -0.17869717,\n",
       "              -0.19484553,  0.44281295, -0.22928451,  0.08204237, -0.3580803 ,\n",
       "               0.10269292,  0.19282097,  0.1106929 , -0.13057429,  0.20965137,\n",
       "              -0.27600926, -0.07982015, -0.0724482 ,  0.28466254,  0.34774673,\n",
       "               0.21870051, -0.1187768 , -0.04054743,  0.06825487, -0.0540548 ,\n",
       "               0.05067201,  0.2416138 ,  0.28996798, -0.05629023,  0.28938693,\n",
       "               0.14381488, -0.10148319,  0.1291127 ,  0.24025682, -0.24560648,\n",
       "              -0.22540884, -0.07713136,  0.43156445,  0.03068691,  0.00522636,\n",
       "              -0.11625473,  0.31627008,  0.36321878,  0.42860976,  0.18228446,\n",
       "              -0.14344074,  0.17441577, -0.1948784 ,  0.05083588, -0.13062392,\n",
       "               0.03476261, -0.38380063, -0.17716713, -0.34140635, -0.22268204,\n",
       "              -0.22251183, -0.01531306, -0.32722294,  0.03333137,  0.41227806,\n",
       "              -0.03684635,  0.18877739, -0.22313917,  0.33265913, -0.02885756,\n",
       "              -0.09560951,  0.07370009,  0.57163835, -0.09520504, -0.05050934,\n",
       "               0.5729222 ,  0.0918311 ,  0.228443  , -0.02115818, -0.13387546,\n",
       "              -0.08336881, -0.39200228,  0.13755588,  0.16059604,  0.28955048,\n",
       "               0.01812588, -0.00927189,  0.24515852, -0.0145057 , -0.0194152 ,\n",
       "               0.07911412,  0.23941122,  0.69368625,  0.03955204, -0.20092918,\n",
       "              -0.36489743, -0.50960094, -0.11231542,  0.0218277 ,  0.08834076,\n",
       "               0.27539074, -0.14842132,  0.07580689, -0.33722943, -0.06677206,\n",
       "              -0.15645142,  0.30426452,  0.25727674,  0.06247857,  0.46452668,\n",
       "               0.12574157, -0.14377037,  0.16934298,  0.1549434 ,  0.2963149 ,\n",
       "              -0.48057267,  0.18475686,  0.55142117, -0.36669505, -0.18243538,\n",
       "               0.02093555, -0.08396434, -0.3551355 ,  0.26416075,  0.07070287,\n",
       "              -0.17116775,  0.07685237,  0.07681531, -0.0232531 ,  0.01676832,\n",
       "              -0.11577734, -0.09691297, -0.29180524, -0.36376697, -0.43427047,\n",
       "              -0.25415137, -0.19721597, -0.1748138 ,  0.07117081, -0.31419098,\n",
       "               0.01392817,  0.2612574 , -0.6450646 , -0.34554616, -0.17854202,\n",
       "               0.2984179 ,  0.14338669,  0.17519017,  0.3162735 , -0.6067804 ,\n",
       "               0.12344571,  0.10243893, -0.11282369,  0.07723231,  0.28034124,\n",
       "               0.24545191, -0.18186133, -0.32715255, -0.17372766, -0.3947189 ,\n",
       "               0.09318537,  0.06098233,  0.35805616,  0.0104751 , -0.49890056,\n",
       "              -0.2854698 ,  0.5078728 , -0.36748132,  0.25191614,  0.39356038,\n",
       "               0.12808253, -0.14135464, -0.22951853, -0.15520513,  0.19510649,\n",
       "              -0.15655878, -0.05658114,  0.01805558, -0.3284337 ,  0.07901906,\n",
       "               0.12847534, -0.14662   ,  0.05310565, -0.02615595,  0.40956768,\n",
       "               0.09952331,  0.19350278, -0.04582172, -0.00520786,  0.20530097,\n",
       "              -0.06763895, -0.08834121,  0.26410016, -0.07573682, -0.13006562,\n",
       "              -0.25447303, -0.07432652,  0.2506453 ,  0.17403512,  0.04627246,\n",
       "               0.00893575, -0.04989505,  0.29267564,  0.33917207, -0.00111914,\n",
       "              -0.06968742,  0.13587844, -0.03811643,  0.09985418, -0.15130968],\n",
       "             dtype=float32)                                                    ,\n",
       "       ...,\n",
       "       array([ 0.20909162,  0.11157483, -0.03535121,  0.00180802,  0.15644217,\n",
       "              -0.17052656, -0.2571029 , -0.1691622 , -0.04002799, -0.10451718,\n",
       "              -0.2251453 ,  0.08023472, -0.44632268,  0.31779   ,  0.09158883,\n",
       "               0.07889149, -0.16317864, -0.05450262, -0.22591811,  0.3539129 ,\n",
       "              -0.17079712, -0.12878767,  0.09984273, -0.01419975, -0.0215985 ,\n",
       "              -0.0362445 ,  0.06276843,  0.56493175,  0.11052399,  0.00083158,\n",
       "              -0.30063578, -0.08109673, -0.15144508,  0.4776952 ,  0.3943193 ,\n",
       "               0.08849397, -0.10367759,  0.13545945,  0.19841282,  0.20639141,\n",
       "              -0.13326968, -0.22706248,  0.04613949,  0.42385316,  0.11638435,\n",
       "              -0.33242962,  0.3503039 ,  0.12170962, -0.61643463, -0.01428545,\n",
       "               0.2224003 ,  0.22522914, -0.16649002,  0.06800322, -0.27361712,\n",
       "              -0.31768832,  0.10380843,  0.06755824,  0.08985346, -0.43956992,\n",
       "              -0.12924986,  0.29404527, -0.2694415 , -0.33989623,  0.07635354,\n",
       "               0.07010745,  0.14278966,  0.25515464,  0.21403466,  0.12008458,\n",
       "               0.40817466, -0.3438875 , -0.22564913, -0.17059544,  0.03265072,\n",
       "               0.10176772, -0.07025258,  0.18420756,  0.0182162 , -0.16526015,\n",
       "              -0.31838265, -0.43282738, -0.0333369 , -0.17517394,  0.2783422 ,\n",
       "               0.24229768, -0.52076954,  0.43966457, -0.14187391,  0.3719359 ,\n",
       "              -0.13678622,  0.12591733, -0.23524125,  0.45185265, -0.28862014,\n",
       "              -0.17880522, -0.22998562,  0.34767848, -0.5049263 , -0.31962082,\n",
       "              -0.34580067,  0.27403888, -0.4545216 , -0.1311597 , -0.7056447 ,\n",
       "               0.36132497,  0.10763715,  0.01478078, -0.25587213, -0.06319105,\n",
       "              -0.05967103,  0.075737  ,  0.17071384,  0.39792627,  0.01079133,\n",
       "               0.04318736,  0.30061674, -0.08317255,  0.21448967, -0.05167218,\n",
       "               0.11465837,  0.3183741 , -0.17856756, -0.16570275, -0.10578428,\n",
       "               0.2614162 , -0.18231985, -0.1743334 ,  0.6289415 , -0.34399232,\n",
       "              -0.01488848, -0.00708593,  0.43183246,  0.02925323, -0.23104751,\n",
       "               0.18793482, -0.00917837,  0.20760742, -0.06554499,  0.2242314 ,\n",
       "               0.16831186,  0.11412675, -0.21289146,  0.18085095, -0.02134417,\n",
       "              -0.10241501, -0.3555465 , -0.42738795, -0.40711328, -0.274323  ,\n",
       "               0.05484907,  0.23737295, -0.34667376, -0.11692853,  0.26762462,\n",
       "               0.40069386,  0.37920302, -0.45908687,  0.03269634, -0.13037892,\n",
       "               0.00117163,  0.07411767,  0.16914771, -0.11574362, -0.0937278 ,\n",
       "               0.34396568, -0.1363715 ,  0.11442349,  0.23337436,  0.07235027,\n",
       "               0.2624209 , -0.22380622, -0.40064996,  0.0879598 , -0.01858522,\n",
       "              -0.08794321, -0.13801028,  0.16064736,  0.14478554, -0.21531434,\n",
       "               0.22927262, -0.19790521,  0.48521864,  0.10119172, -0.18468338,\n",
       "              -0.3372183 , -0.05521358,  0.32363698, -0.16166463, -0.16446696,\n",
       "               0.3725821 , -0.26508433,  0.02724645, -0.52054894,  0.2910821 ,\n",
       "              -0.00978226,  0.07558786, -0.03675538,  0.03015795,  0.1970141 ,\n",
       "              -0.49833646,  0.00662138,  0.16473547,  0.31748906,  0.12983131,\n",
       "              -0.28661412,  0.24249767,  0.62421566, -0.22769651, -0.25711048,\n",
       "               0.24650785,  0.25612226,  0.37529665,  0.47308323,  0.0348872 ,\n",
       "              -0.11452874,  0.46764562,  0.30127048, -0.07320198, -0.04253379,\n",
       "               0.08523148,  0.10039822, -0.36344072, -0.25356907, -0.27904084,\n",
       "              -0.3205272 , -0.26334754, -0.1941399 ,  0.16582328,  0.30321345,\n",
       "              -0.33619794,  0.29021716, -0.00086897, -0.21385418,  0.02163756,\n",
       "               0.20893347, -0.00305236,  0.20145135,  0.13969132,  0.31252608,\n",
       "               0.27688608, -0.596675  , -0.41706645, -0.64213574,  0.22130728,\n",
       "              -0.10229938, -0.03392423,  0.09568568,  0.03683792, -0.25345448,\n",
       "              -0.35330737,  0.02741204,  0.52882195, -0.08510716,  0.2451083 ,\n",
       "               0.15374674,  0.13825946, -0.21054836,  0.1668251 ,  0.06359518,\n",
       "              -0.1738491 ,  0.16089962, -0.22973968, -0.4166614 ,  0.3309713 ,\n",
       "              -0.27749127,  0.32604733,  0.17565902, -0.13622904,  0.37564552,\n",
       "               0.04979768, -0.28836864,  0.02381245, -0.1323409 ,  0.18487506,\n",
       "              -0.02908942,  0.46228778, -0.20941526,  0.5225148 ,  0.04935899,\n",
       "              -0.2074269 , -0.22744565,  0.54293436,  0.50178736, -0.19050676,\n",
       "               0.21045217, -0.04561846,  0.02986196, -0.17969349, -0.36808857,\n",
       "              -0.04126607,  0.13685372,  0.12462784,  0.3328269 ,  0.16405743,\n",
       "              -0.11901357, -0.05731452,  0.36276433, -0.04611469,  0.13882664],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([ 0.4155324 , -0.20138614,  0.08051853,  0.09032973, -0.02317188,\n",
       "              -0.01777686, -0.453727  , -0.05290709,  0.33736935, -0.48952413,\n",
       "              -0.18616368,  0.30702418,  0.12855445,  0.49660966,  0.053448  ,\n",
       "              -0.16806675, -0.14330459, -0.35937193,  0.00123627,  0.25875825,\n",
       "              -0.4906964 , -0.41402823, -0.1374088 ,  0.34456223, -0.0432061 ,\n",
       "              -0.05202567, -0.16275804,  0.10309329,  0.22274208, -0.3342042 ,\n",
       "               0.06857876,  0.0564486 ,  0.08672597,  0.36526254,  0.47700897,\n",
       "              -0.3026846 , -0.1444957 ,  0.5655769 ,  0.4028878 ,  0.5600442 ,\n",
       "               0.18074884, -0.17522718, -0.09462405,  0.30617687,  0.07011107,\n",
       "              -0.50448346,  0.2842144 , -0.00997386, -0.02058871,  0.13395616,\n",
       "               0.48650622,  0.1435741 , -0.31168354,  0.11049707,  0.09886999,\n",
       "              -0.04258706,  0.7666473 ,  0.17675172,  0.21965738,  0.1924563 ,\n",
       "               0.13590308,  0.12587309, -0.14351566, -0.46870488, -0.23203823,\n",
       "               0.03031048,  0.18002796, -0.16015124,  0.01664793,  0.09106036,\n",
       "               0.5130393 , -0.73496896, -0.26276034, -0.33208326,  0.21224001,\n",
       "              -0.1831848 ,  0.00996749,  0.06890501, -0.14573675,  0.31715178,\n",
       "              -0.09412824, -0.00731797, -0.07391316, -0.44768164,  0.16803248,\n",
       "              -0.05561383, -0.21682848,  0.3590208 , -0.04206362,  0.2862889 ,\n",
       "              -0.1624896 ,  0.11963006, -0.56079155,  0.46023297, -0.2564288 ,\n",
       "              -0.36296085, -0.26670408,  0.1628007 , -0.59506005, -0.08233336,\n",
       "              -0.11068552,  0.17236048, -0.09939729, -0.01345543, -0.5435774 ,\n",
       "               0.07393676,  0.14288035,  0.43590584, -0.525527  ,  0.01029687,\n",
       "              -0.15311855, -0.0963526 ,  0.28754982,  0.5758307 ,  0.26819113,\n",
       "               0.16511698,  0.15216702,  0.14415199,  0.60092247,  0.00892427,\n",
       "              -0.16960262,  0.34772432, -0.08052631,  0.13314056,  0.07727882,\n",
       "               0.20865573,  0.06869347, -0.26202843,  0.30701432, -0.3985938 ,\n",
       "              -0.16340461,  0.03891985, -0.24389641, -0.12642153, -0.16112821,\n",
       "               0.18760501, -0.00903503,  0.29544365,  0.15752503,  0.04296064,\n",
       "               0.05423956,  0.12193947, -0.32491463,  0.29611015,  0.10082211,\n",
       "              -0.06293964, -0.48047304, -0.46412632, -0.48636633, -0.4974116 ,\n",
       "              -0.04515766,  0.19727485, -0.41716623, -0.22578552,  0.57536834,\n",
       "               0.16512379,  0.17163257, -0.5454239 ,  0.41322196, -0.18877973,\n",
       "              -0.0718653 ,  0.1502369 ,  0.20975396, -0.34761652,  0.1571977 ,\n",
       "               0.4432311 , -0.11762162,  0.02207243,  0.28257343, -0.04830134,\n",
       "               0.00307109, -0.24261576, -0.20147265, -0.19845638, -0.14661114,\n",
       "               0.10358924, -0.08131808,  0.3290893 ,  0.42228356,  0.21766657,\n",
       "               0.27854815,  0.15381785,  0.6445217 , -0.23953484, -0.4024071 ,\n",
       "              -0.18503477, -0.14893048,  0.09830034,  0.02746835, -0.10906499,\n",
       "               0.21926765, -0.5391752 ,  0.0323746 , -0.57416207,  0.0118075 ,\n",
       "              -0.0157934 ,  0.3003715 ,  0.10444736,  0.27273974,  0.09583142,\n",
       "              -0.19664933,  0.07352113,  0.19152787,  0.44349632,  0.08409155,\n",
       "              -0.29217377,  0.1468203 ,  0.5298159 , -0.58545935, -0.22901143,\n",
       "              -0.2501092 , -0.15413624, -0.15980254,  0.134608  , -0.08318409,\n",
       "               0.05580503,  0.26724103,  0.37077975, -0.20255683, -0.07914273,\n",
       "               0.11088066,  0.21009515, -0.28596827, -0.05691328, -0.09836575,\n",
       "              -0.3427406 , -0.20451182, -0.07450783,  0.1594171 ,  0.30251   ,\n",
       "               0.02453769,  0.3001086 , -0.01825355, -0.27967423, -0.27459675,\n",
       "               0.2706002 , -0.19985719,  0.10261873, -0.05363699,  0.01728127,\n",
       "               0.49880207, -0.44981894, -0.23138052, -0.4128243 , -0.3719808 ,\n",
       "               0.04496606, -0.11232238, -0.28568903,  0.10383558,  0.03612066,\n",
       "              -0.23203948,  0.17668253,  0.6558212 ,  0.2478153 ,  0.01534088,\n",
       "               0.00531811,  0.08248993, -0.28513166,  0.3133229 ,  0.1219695 ,\n",
       "              -0.26617742,  0.0320577 , -0.09416783,  0.03084066,  0.06344521,\n",
       "              -0.463214  ,  0.42419124,  0.293907  ,  0.04208717, -0.05336659,\n",
       "               0.2942212 , -0.06276812, -0.06398603, -0.18795946,  0.39665774,\n",
       "              -0.10823879,  0.10084937, -0.34509534,  0.31158715, -0.20049013,\n",
       "               0.10639318,  0.02097531,  0.5201038 ,  0.4077605 , -0.5590379 ,\n",
       "              -0.08864389, -0.34342462, -0.2628232 , -0.11337006, -0.343763  ,\n",
       "               0.24629386,  0.05142593, -0.09513188, -0.01504135, -0.06176614,\n",
       "              -0.00545539, -0.34272572,  0.1293045 , -0.05444872, -0.03204536],\n",
       "             dtype=float32)                                                    ,\n",
       "       array([ 6.35746002e-01, -2.55606592e-01,  2.59034157e-01, -3.29713315e-01,\n",
       "               2.17644736e-01,  4.74782251e-02, -6.61133677e-02,  9.98963788e-02,\n",
       "               3.28124523e-01,  4.56987500e-01,  4.13551703e-02,  3.18560302e-01,\n",
       "              -5.30661523e-01,  6.93145454e-01, -9.58768278e-02,  1.90254867e-01,\n",
       "               2.15365395e-01, -2.43314058e-01,  3.08498740e-01, -2.31694058e-01,\n",
       "               1.66805536e-01, -5.03423475e-02, -1.34488240e-01, -6.63704634e-01,\n",
       "              -2.97270775e-01,  9.98287201e-02,  2.18743607e-02,  6.68418646e-01,\n",
       "               3.62942338e-01,  1.77986205e-01, -4.05745059e-01,  1.66417301e-01,\n",
       "               2.57258080e-02,  7.07844257e-01, -8.33144486e-02,  4.19244468e-01,\n",
       "              -7.67479181e-01, -1.14675179e-01, -8.11060891e-02,  3.12123090e-01,\n",
       "               5.43744028e-01, -4.55499053e-01, -3.25891882e-01,  1.79841779e-02,\n",
       "              -1.52869046e-01, -1.90613478e-01,  1.65842265e-01, -1.91768110e-01,\n",
       "              -4.33143973e-01,  4.08110678e-01,  8.07542562e-01,  2.95011699e-01,\n",
       "              -1.12681709e-01,  1.56001881e-01, -1.02501586e-01,  1.28501132e-01,\n",
       "               3.24427746e-02, -1.69491768e-01,  4.23768520e-01, -5.70132077e-01,\n",
       "               1.57769844e-02,  4.27549332e-01, -5.26984513e-01,  9.07422677e-02,\n",
       "               6.92650676e-03, -2.17553213e-01,  3.55649054e-01,  3.12277198e-01,\n",
       "               1.25182092e-01,  3.04362178e-01,  5.86710274e-01, -3.78102273e-01,\n",
       "               7.18972310e-02, -5.09248972e-01, -4.00268197e-01,  4.50170040e-01,\n",
       "               1.23718590e-01, -2.05285117e-01,  1.41260117e-01, -2.62476087e-01,\n",
       "              -5.31448960e-01, -7.98448980e-01,  1.65624321e-01, -3.96380305e-01,\n",
       "               2.69236326e-01, -1.31614834e-01,  2.99426377e-01,  2.77183741e-01,\n",
       "               2.58805960e-01,  2.95074761e-01,  3.55707278e-04, -6.85645819e-01,\n",
       "               3.07988465e-01,  6.19404435e-01,  2.93679118e-01,  2.55569190e-01,\n",
       "               2.47953892e-01,  1.78842068e-01, -4.53478217e-01,  3.62285942e-01,\n",
       "              -2.41243258e-01, -7.00264517e-03, -3.65049243e-01, -2.87367940e-01,\n",
       "              -3.45077723e-01, -3.34657162e-01, -1.71327189e-01, -2.83182919e-01,\n",
       "              -8.87528211e-02,  1.62314370e-01,  5.54961748e-02,  1.16336979e-01,\n",
       "               2.08424732e-01,  6.40603304e-01,  9.77525413e-01,  3.80451202e-01,\n",
       "              -4.44081277e-01, -2.80690849e-01,  3.56229544e-01,  1.58693269e-02,\n",
       "               3.50279838e-01,  1.24798283e-01,  5.65419436e-01, -2.62243152e-01,\n",
       "              -3.46501708e-01,  4.01907444e-01, -1.94988251e-01,  5.74707389e-02,\n",
       "               2.56420672e-01, -3.40430617e-01, -3.85044605e-01, -1.23109765e-01,\n",
       "               6.35445833e-01, -3.62348676e-01, -2.04659715e-01, -2.38752633e-01,\n",
       "              -7.53684789e-02,  1.61891460e-01,  5.33686876e-01,  1.93601977e-02,\n",
       "              -1.03945732e-01,  7.47126341e-01, -2.12406173e-01,  4.49672416e-02,\n",
       "              -3.42154205e-01,  2.18150839e-01, -2.28285417e-01, -1.87912747e-01,\n",
       "              -4.33740839e-02,  3.23131144e-01, -2.52768725e-01,  2.65638024e-01,\n",
       "              -3.03698093e-01, -5.25462814e-02, -2.83145666e-01, -4.87886965e-01,\n",
       "               7.03960776e-01, -3.65568340e-01, -6.70750618e-01,  8.93886015e-02,\n",
       "               3.14010680e-01, -7.90975913e-02,  3.66423637e-01, -4.37634617e-01,\n",
       "              -3.38035345e-01,  3.41190130e-01, -2.66399384e-01,  2.03143120e-01,\n",
       "              -5.87391615e-01, -6.19793385e-02,  1.91195935e-01,  9.77449790e-02,\n",
       "               3.33806783e-01,  1.34732366e-01,  4.48388040e-01, -2.92438008e-02,\n",
       "              -2.61528850e-01, -3.45691562e-01,  7.84333125e-02, -4.83287930e-01,\n",
       "               1.51407570e-01,  3.57859075e-01,  7.61890292e-01, -1.91842198e-01,\n",
       "              -2.37666026e-01, -4.73725587e-01, -2.91494131e-01,  1.87563211e-01,\n",
       "              -3.58233182e-03, -3.24884176e-01,  1.71013996e-02, -9.74474251e-02,\n",
       "               2.33882904e-01, -2.92096436e-01, -7.51565456e-01, -4.57154103e-02,\n",
       "               9.62203443e-01,  2.78440326e-01, -3.46192956e-01,  3.34328204e-01,\n",
       "              -3.40247229e-02,  2.42785662e-01,  2.00085804e-01,  8.50240886e-02,\n",
       "               4.26437825e-01,  1.09090190e-02,  2.67586231e-01,  8.94881487e-01,\n",
       "               2.58163549e-02, -8.08679685e-02,  4.56950394e-03, -4.10384983e-01,\n",
       "              -4.14837927e-01,  2.91364461e-01, -5.75123914e-03, -5.44803381e-01,\n",
       "              -4.41388674e-02,  6.16949618e-01,  6.09348230e-02,  1.62267447e-01,\n",
       "              -4.65102270e-02,  3.88830781e-01, -5.91989875e-01, -3.34545374e-01,\n",
       "               5.16101122e-02,  1.46112636e-01, -3.94054413e-01,  6.23018406e-02,\n",
       "              -1.18566819e-01,  3.78147990e-01,  1.57744214e-02,  1.80164337e-01,\n",
       "              -2.41937399e-01, -7.56815851e-01,  4.65670153e-02, -8.99579599e-02,\n",
       "              -5.65375447e-01,  2.44158402e-01,  2.97326565e-01, -1.49750262e-01,\n",
       "               5.00837981e-04,  1.73742235e-01,  6.24786094e-02,  2.88120955e-01,\n",
       "               2.80122221e-01,  3.47332098e-02, -1.21171504e-01, -8.53349924e-01,\n",
       "               3.96865547e-01, -3.09951842e-01,  7.29332790e-02,  7.23881066e-01,\n",
       "              -8.98980945e-02, -7.02528134e-02, -1.26290634e-01, -2.92765737e-01,\n",
       "               3.98098588e-01, -2.51022786e-01, -1.02694556e-01,  1.55399442e-02,\n",
       "               1.30183250e-01,  2.88713306e-01, -2.23139212e-01, -1.93642274e-01,\n",
       "               5.98788083e-01, -1.95001468e-01, -3.32213044e-01,  1.37406886e-01,\n",
       "               1.06417432e-01,  4.09588248e-01,  4.62054878e-01,  2.52994061e-01,\n",
       "              -5.57319075e-02,  2.98162907e-01,  2.54733086e-01,  4.32831377e-01,\n",
       "              -2.74709910e-02,  1.51111126e-01, -1.24466471e-01,  2.41687506e-01,\n",
       "              -4.63196754e-01, -6.04107618e-01,  3.80242795e-01,  1.43787175e-01,\n",
       "              -6.56092405e-01, -6.48107290e-01,  5.05471528e-01, -1.79411262e-01,\n",
       "               1.76237881e-01,  5.80631159e-02,  1.66729152e-01,  7.25758448e-02,\n",
       "              -4.17361289e-01,  1.21916212e-01, -4.80276436e-01, -1.35170385e-01,\n",
       "              -2.57163197e-01,  6.12058910e-03,  2.29370564e-01, -1.32553816e-01],\n",
       "             dtype=float32)                                                       ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1471, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 939, in dispatch_data_backend\n",
      "    _check_data_shape(data)\n",
      "  File \"c:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\", line 61, in _check_data_shape\n",
      "    raise ValueError(\"Please reshape the input data into 2-dimensional matrix.\")\n",
      "ValueError: Please reshape the input data into 2-dimensional matrix.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please reshape the input data into 2-dimensional matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32620\\1017257530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# run the random search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# print the best parameters and score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m             )\n\u001b[1;32m-> 1471\u001b[1;33m             train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[0;32m   1472\u001b[0m                 \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\n\u001b[0;32m    447\u001b[0m     way.\"\"\"\n\u001b[1;32m--> 448\u001b[1;33m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_evaluation_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingCallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvalsLog\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[0;32m    744\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;34m'''Dispatch data for DMatrix.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_cudf_ser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0m_check_data_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_check_data_shape\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please reshape the input data into 2-dimensional matrix.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please reshape the input data into 2-dimensional matrix."
     ]
    }
   ],
   "source": [
    "#Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# define your data and labels\n",
    "X = X_np\n",
    "y = y\n",
    "\n",
    "# define the parameter space to search over\n",
    "param_dist = {\n",
    "    'learning_rate': np.arange(0.05, 0.31, 0.05),\n",
    "    'max_depth': np.arange(6,10, 1),\n",
    "    'subsample': np.arange(0.5, 1.0, 0.1)\n",
    "}\n",
    "\n",
    "# create an instance of the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# create a random search object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,  # number of iterations\n",
    "    cv=3,  # number of cross-validation folds\n",
    "    scoring='accuracy',  # evaluation metric\n",
    "    n_jobs=-1,  # use all available CPUs\n",
    "    verbose=3  # display progress messages\n",
    ")\n",
    "\n",
    "# run the random search\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# print the best parameters and score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best ROC AUC score:\", random_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Define X and y\n",
    "X = cleaned_data['encoded_text']\n",
    "y = y\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5,6],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Define XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Define GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_clf, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV object to data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shit runs out of memory oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.19 TiB for an array with shape (393917, 2508978) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20892\\3976151988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Convert sparse matrix to array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Print feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.19 TiB for an array with shape (393917, 2508978) and data type int64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Encode documents using 2-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "encoded_documents = vectorizer.fit_transform(cleaned_data['Text'])\n",
    "\n",
    "\n",
    "# Define CountVectorizer with n-gram range\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform text data\n",
    "X = vectorizer.fit_transform(cleaned_data['Text'])\n",
    "\n",
    "# Convert sparse matrix to array\n",
    "X = np.array(X.toarray())\n",
    "\n",
    "# Print feature names\n",
    "print(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8597515569997293\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST4\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define X and y\n",
    "X = X\n",
    "y = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Train XGBoost classifier on training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(xg_test)\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this one I don't think we can stem ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20892\\3805236029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load GloVe embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mglove_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/path/to/glove.6B.100d.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get embedding vector for a word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m         \"\"\"\n\u001b[1;32m-> 1629\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1954\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1955\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\micha\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_model = KeyedVectors.load_word2vec_format('/path/to/glove.6B.100d.txt', binary=False)\n",
    "\n",
    "# Get embedding vector for a word\n",
    "embedding_vector = glove_model['word']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
