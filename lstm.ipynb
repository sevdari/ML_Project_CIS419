{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Reviews.csv')\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd\n",
    "\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/klejdisevdari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#basic cleaning\n",
    "import time\n",
    "\n",
    "data = data.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"})\n",
    "data = data[data['HelpfulnessNumerator'] <= data['HelpfulnessDenominator']]\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "#removing spaces and stopwords\n",
    "import re\n",
    "# function to clean data\n",
    "def clean_data(X):\n",
    "    temp =[]\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "    start = time.time()\n",
    "    for i, sentence in enumerate(X):\n",
    "        if i%10000 == 0:\n",
    "            print(i, 'Time taken:', time.time()-start)\n",
    "            start = time.time()\n",
    "        sentence = sentence.lower()                 # Converting to lowercase\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        sentence = re.sub(cleanr, ' ', sentence)        #Removing HTML tags\n",
    "        sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "        sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)        #Removing Punctuations\n",
    "\n",
    "        words = [snow.stem(word) for word in sentence.split()]   # Stemming\n",
    "        temp.append(words)\n",
    "\n",
    "    X = temp    \n",
    "\n",
    "    sent = []\n",
    "    for row in X:\n",
    "        sequ = ''\n",
    "        for word in row:\n",
    "            sequ = sequ + ' ' + word\n",
    "        sent.append(sequ)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['Text'], data['Score'] # extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='bar') # check unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y[y<4] = 0 # negative class\n",
    "y[y>=4] = 1 # positive class\n",
    "y.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y) # to convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Time taken: 1.5020370483398438e-05\n",
      "10000 Time taken: 4.28208589553833\n",
      "20000 Time taken: 4.668278932571411\n",
      "30000 Time taken: 4.387677907943726\n",
      "40000 Time taken: 4.543781042098999\n",
      "50000 Time taken: 4.4371418952941895\n",
      "60000 Time taken: 4.673625946044922\n",
      "70000 Time taken: 4.925822973251343\n",
      "80000 Time taken: 4.594944953918457\n",
      "90000 Time taken: 4.531094074249268\n",
      "100000 Time taken: 4.215704917907715\n",
      "110000 Time taken: 4.376190900802612\n",
      "120000 Time taken: 4.788803815841675\n",
      "130000 Time taken: 4.298745155334473\n",
      "140000 Time taken: 4.378087997436523\n",
      "150000 Time taken: 4.532815217971802\n",
      "160000 Time taken: 4.552306890487671\n",
      "170000 Time taken: 4.392742156982422\n",
      "180000 Time taken: 4.354651212692261\n",
      "190000 Time taken: 4.448018789291382\n",
      "200000 Time taken: 4.902785062789917\n",
      "210000 Time taken: 4.437324047088623\n",
      "220000 Time taken: 4.406347990036011\n",
      "230000 Time taken: 4.66995906829834\n",
      "240000 Time taken: 4.16654896736145\n",
      "250000 Time taken: 4.375397205352783\n",
      "260000 Time taken: 4.439316034317017\n",
      "270000 Time taken: 4.595893144607544\n",
      "280000 Time taken: 4.384436845779419\n",
      "290000 Time taken: 4.266684293746948\n",
      "300000 Time taken: 4.5844879150390625\n",
      "310000 Time taken: 4.422237873077393\n",
      "320000 Time taken: 4.388545036315918\n",
      "330000 Time taken: 4.302052974700928\n",
      "340000 Time taken: 4.206309080123901\n",
      "350000 Time taken: 4.306813955307007\n",
      "360000 Time taken: 4.383313179016113\n",
      "370000 Time taken: 4.4634130001068115\n",
      "380000 Time taken: 4.556349992752075\n",
      "390000 Time taken: 4.483492136001587\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = clean_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393917, 393917)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_data), len(y) # checking if the length of cleaned data and y is same# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of validation set 1000 1000\n",
      "Length of validation set 391698 391698\n",
      "\n",
      " Example of bad Review: \n",
      "\n",
      " product arriv label as jumbo salt peanut the peanut were actual small size unsalt not sure if this was an error or if the vendor intend to repres the product as jumbo\n",
      "\n",
      " Example of Good Review: \n",
      "\n",
      " the tea tin is guard the aroma veri well the tast is beautiful: the malva flower do soften the tast and the amount of bergamot is just right the first time i use too much tea and soak it for too long i use as refer darjeel ftgfop first flush sinc then i save on the quantiti of tea leav and soak the tea for onli two minut a delight: the best earl grey i ever had the price is veri competit\n"
     ]
    }
   ],
   "source": [
    "# creating train and validation\n",
    "\n",
    "# get the indicies of the positive and negative classes\n",
    "zero_indicies = np.where(y==0)[0]\n",
    "one_indicies = np.where(y==1)[0]\n",
    "\n",
    "# create validation indicies\n",
    "val_indicies = np.concatenate([zero_indicies[:500], one_indicies[:500]])\n",
    "max_val = np.max(val_indicies)\n",
    "\n",
    "# create the validation data\n",
    "y_val = y[val_indicies]\n",
    "val_data = []\n",
    "for i in val_indicies:\n",
    "    val_data.append(cleaned_data[i])\n",
    "\n",
    "# create train data\n",
    "train_data = cleaned_data[max_val+1:]\n",
    "y_train = y[max_val+1:]\n",
    "\n",
    "print('Length of validation set', len(val_data), len(y_val))\n",
    "print('Length of validation set', len(train_data), len(y_train))\n",
    "\n",
    "# Santiy check\n",
    "print('\\n Example of bad Review: \\n')\n",
    "print(val_data[0])\n",
    "\n",
    "print('\\n Example of Good Review: \\n')\n",
    "print(val_data[-1])\n",
    "\n",
    "# Note that the words are stemmed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(cleaned_data), specials=[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3953, 173]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['hello', 'how']) # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes about 1 minute to read through the whole file and find the words we need. \n",
    "def get_glove_mapping(vocab, file):\n",
    "    \n",
    "    # Gets the mapping of words from the vocabulary to pretrained embeddings\n",
    "    \n",
    "    glove_map = {}\n",
    "    with open(file,'rb') as fi:\n",
    "        for i, l in enumerate(fi):\n",
    "            try:\n",
    "                line = l.decode('utf-8')\n",
    "                line = line.split(' ')\n",
    "                word = line[0]\n",
    "                if word in vocab:\n",
    "                    array = np.array(line[1:], dtype=np.float)\n",
    "                    glove_map[word] = array\n",
    "            except:\n",
    "                # print('some sort of error')\n",
    "                #some lines have urls, we don't need them.\n",
    "                pass\n",
    "    return glove_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_map = get_glove_mapping(vocab,glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(n_embed, d_embed, glove_map):\n",
    "    \n",
    "    # Initialize the weight matrix\n",
    "    weights_matrix = np.random.normal(size=(n_embed, d_embed))\n",
    "\n",
    "    for i, word in enumerate(vocab.get_itos()):\n",
    "      if word in glove_map:\n",
    "        weights_matrix[i] = glove_map[word]\n",
    "    \n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = get_weight_matrix(len(vocab), 300, glove_map).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix[vocab(['hello', 'how'])].shape # sanity check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that convert sentences into Pytorch tensors\n",
    "def sentenceToTensor(line, batch=True):\n",
    "    entries = text_pipeline(line)\n",
    "    tensor = torch.from_numpy(weights_matrix[entries])\n",
    "    if batch:\n",
    "        return tensor.unsqueeze(1)\n",
    "    return tensor\n",
    "\n",
    "def wordToTensor(word):\n",
    "    entries = text_pipeline(word)\n",
    "    return torch.from_numpy(weights_matrix[entries])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving the unbalanced data issue\n",
    "The function below is used in the training loop and it generates senteces of each sentiment with equal probability. This is in an attempt to resolve the unbalanced data issue. Otherwise, the classifer might see a majority of positive sentiment sentences and have a bias towards classifying most sentences as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([31, 1, 300])\n"
     ]
    }
   ],
   "source": [
    "# Get the indicies of the training set\n",
    "zero_indicies = np.where(y_train==0)[0]\n",
    "one_indicies = np.where(y_train==1)[0]\n",
    "\n",
    "def randomTrainingExample(data, batch=True):\n",
    "    # Flip a coin\n",
    "    coin = np.random.uniform()\n",
    "\n",
    "    random = None\n",
    "    if coin > 0.5:\n",
    "        random = np.random.randint(0, len(zero_indicies))\n",
    "        random = zero_indicies[random]\n",
    "    else:\n",
    "         random = np.random.randint(0, len(one_indicies))\n",
    "         random = one_indicies[random]\n",
    "    \n",
    "    # get the training examples\n",
    "    tensor = sentenceToTensor(data[random], batch=batch)\n",
    "    category = torch.tensor([[y_train[random]]], dtype=torch.float)\n",
    "    return category, tensor\n",
    "\n",
    "cat, input = randomTrainingExample(train_data)\n",
    "print(cat.shape, input.shape) # sanity check\n",
    "# input shape should be [no_words, batch, embedding_dim] if batch=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the accuracies of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracyLTSM(model):\n",
    "  with torch.no_grad():\n",
    "    count = 0 # count the correct instances\n",
    "\n",
    "    for i in range(len(val_data)):\n",
    "      # get sentence and convert to tensor\n",
    "      sentence = val_data[i]\n",
    "      sentence = sentenceToTensor(sentence)\n",
    "      category = torch.tensor([[y_val[i]]], dtype=torch.float)\n",
    "\n",
    "      # get prediction\n",
    "      pred = model(sentence)\n",
    "      # print(category.item(), pred.item())\n",
    "\n",
    "      # check accuracy\n",
    "      classification = 1 if pred.item() > 0.5 else 0\n",
    "      if classification == category.item():\n",
    "          count+= 1\n",
    "    \n",
    "    # return the accuracy\n",
    "    return count/len(val_data)\n",
    "# get_accuracyLTSM(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, embedding_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        lstm_out, _ = self.lstm(sentence)\n",
    "        logit = self.hidden2tag(lstm_out[-1])\n",
    "        prob = nn.functional.sigmoid(logit)\n",
    "        return prob\n",
    "\n",
    "model = LSTM(300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (2m 15s) 0.6808\n",
      "Accuracy: 0.644\n",
      "10000 10% (4m 29s) 0.6296\n",
      "Accuracy: 0.632\n",
      "15000 15% (6m 43s) 0.5941\n",
      "Accuracy: 0.597\n",
      "20000 20% (8m 56s) 0.6243\n",
      "Accuracy: 0.713\n",
      "25000 25% (11m 6s) 0.5638\n",
      "Accuracy: 0.577\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "current_loss = 0\n",
    "start = time.time()\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters+1): \n",
    "    # Step 1. Remember that Pytorch accumulates gradients.\n",
    "    # We need to clear them out before each instance\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "    # Tensors of word indices.\n",
    "    category, sentence = randomTrainingExample(train_data, batch=False)\n",
    "    category = category[0]\n",
    "    # Step 3. Run our forward pass.\n",
    "    output = model(sentence)\n",
    "\n",
    "    # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "    #  calling optimizer.step()\n",
    "    loss = loss_function(output, category)\n",
    "    current_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        acc = get_accuracyLTSM(model)\n",
    "        print('%d %d%% (%s) %.4f' % (iter, iter / n_iters * 100, timeSince(start), current_loss/print_every))\n",
    "        print('Accuracy:', acc)\n",
    "        current_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
